model:
  target: unimumo.models.motion_vqvae_with_vision.MotionVQVAE
  params:
    monitor: "val_loss"
    mean_dir: "/home/hanyang/code/fyp/fyp_project/data/peract/mean.npy"
    std_dir: "/home/hanyang/code/fyp/fyp_project/data/peract/std.npy"
    motion_mode: "proprior"  # "default" or "proprior"
    normalize_motion: False
    loss_config:
      target: unimumo.modules.loss.LossWithCrossEntropy
      params:
        lambda_commit: 0.02
        lambda_recon: 1.0
        gripper_weight: 0.01
    encoder_config:
      target: unimumo.modules.motion_vqvae_module.Encoder
      params:
        input_dim: 24
        output_dim: 24
        emb_dim_encoder: [ 24, 24, 24 ]
        downsample: [ 1, 1 ]
        dilation_growth_rate: 2
        depth_per_res_block: 1
        activation: 'relu'
    decoder_config:
      target: unimumo.modules.motion_vqvae_module.Decoder
      params:
        input_dim: 8
        output_dim: 24
        emb_dim_decoder: [ 24, 24, 8 ]
        upsample: [ 1, 1 ]
        dilation_growth_rate: 2
        depth_per_res_block: 1
        activation: 'relu'
    fusor_config:
      target: unimumo.modules.motion_vqvae_module.Encoder
      params:
        input_dim: 536  # output_dim of encoder and decoder plus 512 (latent dim of resnet18)
        output_dim: 24
        emb_dim_encoder: [ 536, 24 ]
        downsample: [ 0 ]
        dilation_growth_rate: 2
        depth_per_res_block: 1
        activation: 'relu'
    vision_encoder_config:
      name: "resnet18"
      n_cameras: 2
      encoder_dim: 512
    quantizer_config:
      dimension: 24
      n_q: 1
      q_dropout: False,
      bins: 128
    optimizer_config:
      optimizer:
        target: AdamW
        params:
          lr: 2e-4
          betas: [ 0.9, 0.99 ]
          weight_decay: 0.0
      lr_scheduler:
        target: CosineAnnealingLR
        params:
          T_max: 20000  # not sure about this
          eta_min: 1e-6


data:
  target: train.DataModuleFromConfig
  params:
    batch_size: 2
    wrap: True
    num_workers: 4
    train:
      target: unimumo.data.motion_vqvae_dataset_with_vision.MotionVQVAEDataset
      params:
        split: "train"
        data_dir: "/home/hanyang/code/fyp/fyp_project/data/peract"
        preload_data: True
        apply_rgb: True
        apply_depth: False
        apply_pc: False
        cameras: [ "front", "wrist" ]
        image_size: "224,224"
        chunk_size: 4
        n_chunk_per_traj: 4
        compression_rate: 4
        use_chunk: False
        load_proprioception: True

    validation:
      target: unimumo.data.motion_vqvae_dataset_with_vision.MotionVQVAEDataset
      params:
        split: "val"
        data_dir: "/home/hanyang/code/fyp/fyp_project/data/peract"
        preload_data: True
        apply_rgb: True
        apply_depth: False
        apply_pc: False
        cameras: [ "front", "wrist" ]
        image_size: "224,224"
        chunk_size: 4
        n_chunk_per_traj: 4
        compression_rate: 4
        use_chunk: False
        load_proprioception: True


lightning:
  callbacks:
    video_logger:
      target: unimumo.loggers_vqvae.TrajectoryLogger
      params:
        save_video: false
        num_videos: 1
        save_freq_epoch: 200
        rlb_config:
          data_path: "/home/hanyang/code/fyp/fyp_project/data/peract"
          image_size: "224,224"
          apply_rgb: True
          apply_pc: False

  trainer:
    benchmark: True
    devices: 1
    num_nodes: 1
    strategy: ddp
